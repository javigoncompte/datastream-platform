"""
This type stub file was generated by pyright.
"""

from typing import Any, Dict
from databricks_langchain.chat_models import ChatDatabricks
from langchain.schema.runnable import RunnableSerializable

system_msg = ...
evaluation_criteria = ...
evaluation_criteria_from_description = ...
def execute_llm_eval(llm: ChatDatabricks, candidate_criteria_prompt: str, positive_example: str | None = ..., negative_example: str | None = ...) -> RunnableSerializable:
    """Builds the evaluation prompt similar to executeLLMEval in ChainForge.

    Args:
        criteria_text: The criteria text to evaluate against

    Returns:
        The formatted evaluation prompt matching TypeScript implementation
    """
    ...

def build_context_prompt_for_vars_metavars(vars_and_metavars: Dict[str, Any]) -> str:
    """Builds a context prompt explaining available variables and their values.

    Args:
        vars_and_metavars: Dictionary containing variables and their values

    Returns:
        Formatted string explaining available variables
    """
    ...

def build_function_gen_prompt(criteria_description: str, eval_method: str, prompt_template: str, bad_example: list[str] | None = ..., vars_context: dict[str, Any] | None = ...) -> str:
    """Builds the function generation prompt similar to buildFunctionGenPrompt in ChainForge.

    Args:
        criteria_shortname: Brief title for the criteria
        criteria_description: Full description of the criteria
        eval_method: "expert" or "code"
        prompt_template: Original LLM pipeline prompt template
        bad_example: Optional example response that doesn't meet criteria
        vars_context: Optional context about template variables

    Returns:
        The formatted prompt for generating evaluation functions
    """
    ...

def build_eval_code_generation_prompt(context: str, spec_prompt: str, many_funcs: bool = ..., only_boolean_funcs: bool = ...) -> str:
    """Builds a prompt for generating evaluation code.

    Args:
        many_funcs: Whether to generate multiple functions
        only_boolean_funcs: Whether functions can only return booleans
        context: Additional context for the prompt
        spec_prompt: User's specification for the evaluation

    Returns:
        Formatted prompt string
    """
    ...

