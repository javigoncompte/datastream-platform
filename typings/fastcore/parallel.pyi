"""
This type stub file was generated by pyright.
"""

import concurrent.futures
from .imports import *
from .basics import *
from .foundation import *
from .meta import *
from .xtras import *

"""Threading and multiprocessing functions"""
__all__ = ['threaded', 'startthread', 'startproc', 'parallelable', 'ThreadPoolExecutor', 'ProcessPoolExecutor', 'parallel', 'parallel_async', 'run_procs', 'parallel_gen']
if sys.platform == 'darwin' and IN_NOTEBOOK:
    ...
def threaded(process=...): # -> _Wrapped[..., Any, ..., Process | Thread] | Callable[..., _Wrapped[..., Any, ..., Process | Thread]]:
    "Run `f` in a `Thread` (or `Process` if `process=True`), and returns it"
    ...

def startthread(f): # -> Process | Thread:
    "Like `threaded`, but start thread immediately"
    ...

def startproc(f): # -> Process | Thread:
    "Like `threaded(True)`, but start Process immediately"
    ...

def parallelable(param_name, num_workers, f=...): # -> bool:
    ...

class ThreadPoolExecutor(concurrent.futures.ThreadPoolExecutor):
    "Same as Python's ThreadPoolExecutor, except can pass `max_workers==0` for serial execution"
    def __init__(self, max_workers=..., on_exc=..., pause=..., **kwargs) -> None:
        ...
    
    def map(self, f, items, *args, timeout=..., chunksize=..., **kwargs): # -> map[Any] | Iterator[Any] | None:
        ...
    


@delegates()
class ProcessPoolExecutor(concurrent.futures.ProcessPoolExecutor):
    "Same as Python's ProcessPoolExecutor, except can pass `max_workers==0` for serial execution"
    def __init__(self, max_workers=..., on_exc=..., pause=..., **kwargs) -> None:
        ...
    
    def map(self, f, items, *args, timeout=..., chunksize=..., **kwargs): # -> map[Any] | Iterator[Any] | None:
        ...
    


def parallel(f, items, *args, n_workers=..., total=..., progress=..., pause=..., method=..., threadpool=..., timeout=..., chunksize=..., **kwargs): # -> L:
    "Applies `func` in parallel to `items`, using `n_workers`"
    ...

async def parallel_async(f, items, *args, n_workers=..., timeout=..., chunksize=..., on_exc=..., **kwargs): # -> list[Any]:
    "Applies `f` to `items` in parallel using asyncio and a semaphore to limit concurrency."
    ...

def run_procs(f, f_done, args): # -> Generator[Any, Any, None]:
    "Call `f` for each item in `args` in parallel, yielding `f_done`"
    ...

def parallel_gen(cls, items, n_workers=..., **kwargs): # -> Generator[tuple[int, Any] | Any, Any, None]:
    "Instantiate `cls` in `n_workers` procs & call each on a subset of `items` in parallel."
    ...

