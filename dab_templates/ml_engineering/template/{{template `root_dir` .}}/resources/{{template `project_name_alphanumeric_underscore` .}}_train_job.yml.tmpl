
# The train job for {{template `project_name_alphanumeric_underscore` .}}
resources:
  jobs:
    {{template `project_name_alphanumeric_underscore` .}}_train_job:
      name: {{template `project_name_alphanumeric_underscore` .}}_train_job
      queue:
        enabled: true
      max_concurrent_runs: 1
      email_notifications:
        on_failure:
          - ${var.email_notification}    
      job_clusters:
        - job_cluster_key: ${var.job_cluster_key}
          new_cluster:
            spark_version: ${var.spark_version}
            driver_node_type_id: "i3.xlarge"
            node_type_id: "i3.xlarge"
            autoscale:
              min_workers: 2
              max_workers: 4
            aws_attributes:
              first_on_demand: 1
              availability: "SPOT_WITH_FALLBACK"
              zone_id: "auto"
              spot_bid_price_percent: 100
              ebs_volume_count: 0
            spark_conf:
              spark.databricks.delta.enableChangeDataFeed: "true"
              spark.databricks.delta.schema.autoMerge.enabled: "true"
              spark.databricks.delta.autoCompact.enabled: "true"
              spark.databricks.delta.optimizeWrite.enabled: "true"
      tasks:        
        - task_key: model_train_task
          job_cluster_key: ${var.job_cluster_key}
          max_retries: ${var.max_retries}
          libraries:
            - whl: ../dist/*.whl
          spark_python_task:
            python_file: ../dataplatform/{{template `project_name_alphanumeric_underscore` .}}/tasks/model_train_task.py
            parameters:
              - "{{`{{job.parameters.model_name}}`}}"
              - "{{`{{job.parameters.deployment_job_id}}`}}"

      parameters:
        - name: model_name
          default: ${bundle.name}
        - name: deployment_job_id
          default: ${resources.jobs.{{template `project_name_alphanumeric_underscore` .}}_deployment_job.id}
