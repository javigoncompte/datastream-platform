"""Model training for {{template `project_name_alphanumeric_underscore` .}}."""

# COMMAND ----------
from typing import Any, Dict

import altair as alt
import mlflow
import pandas as pd
import polars as pl
from dataplatform.core.logger import get_logger
from dataplatform.core.mlflow_experiment import setup_mlflow_experiment

logger = get_logger(__name__)
model_experiment = setup_mlflow_experiment(
    "{{template `project_name_alphanumeric_underscore` .}}", autolog_modules=["pyfunc"]
)

# COMMAND ----------
# ==============================================================================
# CONFIGURATION
# ==============================================================================
# All tunable parameters should be defined here.
# Example:
# PARAMS = {"C": 1.0, "penalty": "l1", "solver": "liblinear"}


# COMMAND ----------
# ==============================================================================
# PLOTTING
# ==============================================================================


def plot_predictions_example(preds: pd.DataFrame) -> "alt.Chart":
    """Example function to plot model predictions."""

    chart = (
        alt.Chart(preds)
        .mark_bar()
        .encode(x="category", y="value")
        .properties(title="Example Predictions")
    )
    return chart


def save_and_log_chart(chart: "alt.Chart", filename: str) -> None:
    """Save an Altair chart to a file and log it to MLflow."""
    chart.save(filename, format="png", scale_factor=2)
    mlflow.log_image(filename, f"{filename}.png")


def log_plots_to_mlflow(charts: Dict[str, "alt.Chart"]) -> None:
    """Log a dictionary of Altair charts to MLflow."""
    logger.info("Logging plots to MLflow")
    for filename, chart in charts.items():
        save_and_log_chart(chart, filename)


# COMMAND ----------
# ==============================================================================
# Preprocessing
# ==============================================================================


def create_train_dataset() -> pd.DataFrame:
    """Load and prepare the training dataset."""
    logger.info("Created training dataset")

    pass


def preprocessing_data(df: pd.DataFrame) -> Dict[str, Any]:
    """Process features for the model."""
    logger.info("Running preprocessing")
    # TODO: Implement preprocessing.

    pass


# COMMAND ----------
# ==============================================================================
# MODEL TRAINING
# ==============================================================================
class Model(mlflow.pyfunc.PythonModel):
    def __init__(self, model, transformer):
        self.fitted_model = model
        self.transformer = transformer

    def predict(self, model_input, params=None):
        # Do your preprocessing here for data formats if needed
        model_input = pl.from_pandas(model_input)
        model_input = self.transformer.transform(model_input)
        feature_names = self.transformer.get_feature_names_out()
        model_input = pl.DataFrame(
            model_input, schema={name: pl.Float32 for name in feature_names}
        )
        model_input = model_input.to_pandas(use_pyarrow_extension_array=True)
        if params:
            return self.fitted_model.predict(model_input, **params)
        else:
            return self.fitted_model.predict(model_input)


def build_model():
    # TODO: Implement the model
    pass


# Model will be saved to mlflow under {{template `project_name_alphanumeric_underscore` .}}
# in Experiments Tab in Databricks
def train_model() -> Any:
    """Train the model and return training results."""
    logger.info("Starting model training")

    df = create_train_dataset()
    train_data = preprocessing_data(df)
    model = build_model()

    # TODO: Implement actual training logic
    # Return model and any training metrics
    return model, train_data


# COMMAND ----------
# ==============================================================================
# Model Logging and Evaluation
# ==============================================================================


@model_experiment
def log_evaluate_model() -> Any:
    """Log model evaluation metrics and artifacts."""
    # TODO: log_params, log_metrics, log_input, log_model
    # Return model URI and metrics
    return "model_uri", {}


# COMMAND ----------
def run_model_training() -> Any:
    # TODO: Implement train_model()
    train_result = train_model()
    
    # TODO: Implement log_evaluate_model()
    evaluation_result = log_evaluate_model()
    
    logger.info(f"Training completed: {train_result}")
    logger.info(f"Evaluation completed: {evaluation_result}")
    return train_result, evaluation_result

